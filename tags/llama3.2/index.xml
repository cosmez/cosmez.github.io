<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llama3.2 on λ Cosme Zamudio</title>
    <link>/tags/llama3.2/</link>
    <description>Recent content in Llama3.2 on λ Cosme Zamudio</description>
    <generator>Hugo</generator>
    <language>es-MX</language>
    <lastBuildDate>Thu, 26 Sep 2024 22:14:18 -0700</lastBuildDate>
    <atom:link href="/tags/llama3.2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Llama3.2 3b Español</title>
      <link>/blog/llama3.2-3b-spanish/</link>
      <pubDate>Thu, 26 Sep 2024 22:14:18 -0700</pubDate>
      <guid>/blog/llama3.2-3b-spanish/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;/images/mexican-llama.webp&#34; width=&#34;400&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Este tutorial está basado en una transcripción de una serie de videos de live-coding con el modelo whisper y ChatGPT o1-preview. &lt;a href=&#34;https://www.youtube.com/playlist?list=PLew4gWxBdrWeCGKv-eqYCcJYcKybZU33d&#34;&gt;Playlist&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/cosmez/Llama3.2Tests&#34;&gt;Codigo Fuente Completo del Articulo&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;introducción&#34;&gt;Introducción&lt;/h2&gt;&#xA;&lt;p&gt;Hasta ahora, todos los modelos de lenguaje pequeño que he intentado utilizar tienen el problema de no ser muy efectivos en español. Si bien pueden ser útiles para herramientas o para realizar cadenas de pensamiento y diferentes formas de prompts, si no responden adecuadamente en español, no tiene sentido usarlos localmente.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
