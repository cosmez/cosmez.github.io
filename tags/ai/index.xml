<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ai on λ Cosme Zamudio</title>
    <link>/tags/ai/</link>
    <description>Recent content in Ai on λ Cosme Zamudio</description>
    <generator>Hugo</generator>
    <language>es-MX</language>
    <lastBuildDate>Sat, 09 Nov 2024 16:17:11 -0700</lastBuildDate>
    <atom:link href="/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tokenformer</title>
      <link>/blog/tokenformer/</link>
      <pubDate>Sat, 09 Nov 2024 16:17:11 -0700</pubDate>
      <guid>/blog/tokenformer/</guid>
      <description>&lt;h2 id=&#34;tokenformer&#34;&gt;TokenFormer&lt;/h2&gt;&#xA;&lt;p&gt;La arquitectura Transformer han dominado la inteligencia artificial gracias a su capacidad para manejar datos y relaciones complejas. Sin embargo, enfrentan dos grandes desafíos: la capacidad de aprender en tiempo real y el alto costo energético de su entrenamiento. &lt;a href=&#34;https://arxiv.org/abs/2410.23168&#34;&gt;TokenFormer&lt;/a&gt; (wang2024tokenformer) es una nueva arquitectura diseñada para resolver estos problemas.&lt;/p&gt;&#xA;&lt;h3 id=&#34;neuroplasticidad-en-redes-neuronales&#34;&gt;Neuroplasticidad en Redes Neuronales&lt;/h3&gt;&#xA;&lt;p&gt;Uno de los mayores desafíos en la evolución de las redes neuronales es su limitada neuroplasticidad, es decir, la capacidad de integrar conocimiento nuevo sin perder lo ya aprendido. TokenFormer soluciona esto reutilizando parámetros previamente entrenados y añadiendo nuevos, lo que permite un aprendizaje progresivo sin necesidad de reentrenar desde cero.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Datasets en Español.</title>
      <link>/blog/datasets-abiertos/</link>
      <pubDate>Sat, 09 Nov 2024 16:12:48 -0700</pubDate>
      <guid>/blog/datasets-abiertos/</guid>
      <description>&lt;h2 id=&#34;datasets-en-español&#34;&gt;Datasets en Español&lt;/h2&gt;&#xA;&lt;p&gt;He tenido la oportunidad de trabajar con inteligencia artificial en México y he detectado una necesidad: La falta de datasets abiertos en español para entrenar modelos de lenguaje y deep learning.&lt;/p&gt;&#xA;&lt;p&gt;Esta situación limita el desarrollo de la tecnología en México, pues las herramientas de IA existentes se basan principalmente en datos en inglés.&lt;/p&gt;&#xA;&lt;h3 id=&#34;ejemplo-paddle-ocr&#34;&gt;Ejemplo: Paddle OCR&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/PaddlePaddle/PaddleOCR/releases/download/v2.8.0/PaddleOCR_logo.png&#34; alt=&#34;PaddleOCR&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Si actualmente están buscando la forma más eficiente de realizar OCR utilizando inteligencia artificial, una de las mejores opciones disponibles es &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR&#34;&gt;PaddleOCR&lt;/a&gt;. PaddleOCR es un toolkit de OCR basado en la librería PaddlePaddle de Baidu.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Future of Ai Is Agentic</title>
      <link>/blog/the-future-of-ai-is-agentic/</link>
      <pubDate>Sat, 09 Nov 2024 16:10:32 -0700</pubDate>
      <guid>/blog/the-future-of-ai-is-agentic/</guid>
      <description>&lt;h2 id=&#34;the-future-of-ai-is-agentic&#34;&gt;The future of AI is agentic&lt;/h2&gt;&#xA;&lt;p&gt;Es la primera frase de un nuevo proyecto de Microsoft Research llamado &lt;strong&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/&#34;&gt;Magnetic-One&lt;/a&gt;&lt;/strong&gt;.  Magnetic-One es un orquestador de agentes.&lt;/p&gt;&#xA;&lt;p&gt;Hace unos días también se presentó una propuesta con una tesis llamada &lt;strong&gt;&lt;a href=&#34;https://agoraprotocol.org/&#34;&gt;Agora Protocol&lt;/a&gt;&lt;/strong&gt;, un protocolo multiplataforma, simple y diseñado para la comunicación eficiente entre agentes de modelos de lenguaje (LLM).&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://imgs.xkcd.com/comics/standards.png&#34; alt=&#34;standards&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Al igual que estos dos, hay varios frentes que se están enfocando en la &amp;ldquo;agentización&amp;rdquo; de los modelos de lenguaje. Microsoft, IBM, Google y otros han hablado en sus recientes keynotes o han lanzado proyectos para hacer esto posible.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Llama3.2 3b Español</title>
      <link>/blog/llama3.2-3b-spanish/</link>
      <pubDate>Thu, 26 Sep 2024 22:14:18 -0700</pubDate>
      <guid>/blog/llama3.2-3b-spanish/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;/images/mexican-llama.webp&#34; width=&#34;400&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Este articulo está basado en una transcripción de una serie de videos de live-coding con el modelo whisper y ChatGPT o1-preview. &lt;a href=&#34;https://www.youtube.com/playlist?list=PLew4gWxBdrWeCGKv-eqYCcJYcKybZU33d&#34;&gt;Playlist&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/cosmez/Llama3.2Tests&#34;&gt;Codigo Fuente Completo del Articulo&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;introducción&#34;&gt;Introducción&lt;/h2&gt;&#xA;&lt;p&gt;Hasta ahora, todos los modelos de lenguaje pequeño que he intentado utilizar tienen el problema de no ser muy efectivos en español. Si bien pueden ser útiles para herramientas o para realizar cadenas de pensamiento y diferentes formas de prompts, si no responden adecuadamente en español, no tiene sentido usarlos localmente.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cómo Crear un Chatbot con C#, Unum USearch y OpenAI</title>
      <link>/blog/como-crear-chatbot-csharp-usearch-openai/</link>
      <pubDate>Sun, 22 Sep 2024 15:55:14 -0700</pubDate>
      <guid>/blog/como-crear-chatbot-csharp-usearch-openai/</guid>
      <description>&lt;h2 id=&#34;cómo-crear-un-chatbot-con-c-unum-usearch-y-openai&#34;&gt;Cómo Crear un Chatbot con C#, Unum USearch y OpenAI&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Este tutorial está basado en una transcripción de un video generada con el modelo whisper y ChatGPT o1-preview &lt;a href=&#34;https://www.youtube.com/watch?v=GGt_x7Lekp8&#34;&gt;Video Completo&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/cosmez/ChatBotExample&#34;&gt;Codigo Completo&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Una de las solicitudes más comunes de los clientes interesados en trabajar con inteligencia artificial es desarrollar un chatbot que pueda responder en lenguaje natural. En este artículo, exploraremos cómo implementar un chatbot utilizando las librerías proporcionadas por OpenAI y una pequeña base de datos vectorial llama USearch. Este enfoque no es el único, pero es una forma efectiva de abordar el problema.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
